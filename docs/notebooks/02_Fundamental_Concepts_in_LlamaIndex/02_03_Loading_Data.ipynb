{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install llama-index==0.12.49 html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÇ **Loading Data**\n",
    "\n",
    "Preparing your data for an LLM involves an ingestion pipeline similar to ML data cleaning or traditional ETL processes.\n",
    "\n",
    "### **Ingestion Pipeline Stages**\n",
    "  - üì• Load the data\n",
    "  - üîß Transform the data\n",
    "  - üóÉÔ∏è Index and store the data\n",
    "\n",
    "\n",
    "Let's start by downloading some example files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded pg1.txt to ../data/pg1.txt\n",
      "Downloaded pg2.txt to ../data/pg2.txt\n",
      "Downloaded pg3.txt to ../data/pg3.txt\n",
      "Downloaded pg4.txt to ../data/pg4.txt\n",
      "Downloaded pg5.txt to ../data/pg5.txt\n",
      "Downloaded pg6.txt to ../data/pg6.txt\n",
      "Downloaded pg7.txt to ../data/pg7.txt\n",
      "Downloaded pg8.txt to ../data/pg8.txt\n",
      "Downloaded pg9.txt to ../data/pg9.txt\n",
      "Downloaded pg10.txt to ../data/pg10.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Base URL for Project Gutenberg texts\n",
    "base_url = \"https://www.gutenberg.org/cache/epub/{book_id}/pg{book_id}.txt\"\n",
    "\n",
    "# Directory to save the downloaded files\n",
    "directory = Path(\"../data\")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate a list of book IDs to download\n",
    "book_ids = range(1, 11)  # This will create a range from 1 to 10\n",
    "\n",
    "# Generate URLs for each book ID\n",
    "urls = [base_url.format(book_id=book_id) for book_id in book_ids]\n",
    "\n",
    "# Download each file and save it in the specified directory\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the filename from the URL using the book ID and create a file name\n",
    "        book_id = url.split('/')[-2]  # Extracts the book ID from the URL\n",
    "        filename = f\"pg{book_id}.txt\"\n",
    "        file_path = directory / filename\n",
    "        # Save the file to the specified directory\n",
    "        file_path.write_text(response.text)\n",
    "        print(f\"Downloaded {filename} to {file_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {url}. HTTP status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì• Load the data\n",
    "\n",
    "To use data with an LLM, first load it using data connectors, known as `Readers` in LlamaIndex, which format data into `Document` objects containing data and metadata.\n",
    "\n",
    "üìö **SimpleDirectoryReader**:\n",
    "  - The most straightforward loader is `SimpleDirectoryReader``.\n",
    "  - Built into LlamaIndex, it reads various formats (Markdown, PDFs, Word documents, PowerPoint decks, images, audio, video) from every file in a directory, creating documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from os import path, getcwd\n",
    "dir = path.join(getcwd(), \"..\", \"data\")\n",
    "documents = SimpleDirectoryReader(dir).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2109"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.schema.Document"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': '24ad0573-d5cd-476f-b60c-f10d31791887',\n",
       " 'embedding': None,\n",
       " 'metadata': {'page_label': '4',\n",
       "  'file_name': 'almanack_of_naval_ravikant.pdf',\n",
       "  'file_path': '/Users/nastassja.bellisario/Desktop/github/hands-on-ai-rag-using-llamaindex-3830207/02_Fundamental_Concepts_in_LlamaIndex/../data/almanack_of_naval_ravikant.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 1884309,\n",
       "  'creation_date': '2025-07-19',\n",
       "  'last_modified_date': '2025-07-19'},\n",
       " 'excluded_embed_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'excluded_llm_metadata_keys': ['file_name',\n",
       "  'file_type',\n",
       "  'file_size',\n",
       "  'creation_date',\n",
       "  'last_modified_date',\n",
       "  'last_accessed_date'],\n",
       " 'relationships': {},\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_separator': '\\n',\n",
       " 'text_resource': MediaResource(embeddings=None, data=None, text='Copyright ¬© 2020 EriC JorgEnson\\nAll rights reserved.\\nthE AlmAn ACk of nA vAl rA vikAnt\\nA Guide to Wealth and Happiness\\nisBn 978-1-5445-1422-2 Hardcover\\n 978-1-5445-1421-5 Paperback\\n 978-1-5445-1420-8 Ebook\\nThis book has been created as a public service. It is available for \\nfree download in pdf and e-reader versions on Navalmanack.com. \\nNaval is not earning any money on this book. Naval has essays, \\npodcasts and more at Nav.al and is on Twitter @Naval.', path=None, url=None, mimetype=None),\n",
       " 'image_resource': None,\n",
       " 'audio_resource': None,\n",
       " 'video_resource': None,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[3].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manually Create Document Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "manual_document = Document(text=\"This is an example of a manual document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': 'd2a9a8d8-3f5b-4aba-9f0c-b9e3253f2517',\n",
       " 'embedding': None,\n",
       " 'metadata': {},\n",
       " 'excluded_embed_metadata_keys': [],\n",
       " 'excluded_llm_metadata_keys': [],\n",
       " 'relationships': {},\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_separator': '\\n',\n",
       " 'text_resource': MediaResource(embeddings=None, data=None, text='This is an example of a manual document', path=None, url=None, mimetype=None),\n",
       " 'image_resource': None,\n",
       " 'audio_resource': None,\n",
       " 'video_resource': None,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_document.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding metadata\n",
    "\n",
    "You can add metadata in the document constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_document_with_metadata = Document(\n",
    "    text=\"This is an example of a manual document\",\n",
    "    metadata={\"filename\": \"made-up-file-name\", \"category\": \"imaginary-category\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': '5fddad58-fd7c-4fb2-b875-cc6946e2a68c',\n",
       " 'embedding': None,\n",
       " 'metadata': {'filename': 'made-up-file-name',\n",
       "  'category': 'imaginary-category'},\n",
       " 'excluded_embed_metadata_keys': [],\n",
       " 'excluded_llm_metadata_keys': [],\n",
       " 'relationships': {},\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_separator': '\\n',\n",
       " 'text_resource': MediaResource(embeddings=None, data=None, text='This is an example of a manual document', path=None, url=None, mimetype=None),\n",
       " 'image_resource': None,\n",
       " 'audio_resource': None,\n",
       " 'video_resource': None,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_document_with_metadata.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or after the document is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_document.metadata={\"filename\": \"made-up-file-name\", \"category\": \"imaginary-category\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_': 'd2a9a8d8-3f5b-4aba-9f0c-b9e3253f2517',\n",
       " 'embedding': None,\n",
       " 'metadata': {'filename': 'made-up-file-name',\n",
       "  'category': 'imaginary-category'},\n",
       " 'excluded_embed_metadata_keys': [],\n",
       " 'excluded_llm_metadata_keys': [],\n",
       " 'relationships': {},\n",
       " 'metadata_template': '{key}: {value}',\n",
       " 'metadata_separator': '\\n',\n",
       " 'text_resource': MediaResource(embeddings=None, data=None, text='This is an example of a manual document', path=None, url=None, mimetype=None),\n",
       " 'image_resource': None,\n",
       " 'audio_resource': None,\n",
       " 'video_resource': None,\n",
       " 'text_template': '{metadata_str}\\n\\n{content}'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_document.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Transform the data\n",
    "\n",
    "After loading, we must process and transform data for retrieval. We need to transform the list of `Document` objects into `Node` objects \n",
    "\n",
    "- ‚úÇÔ∏è Include chunking, extracting metadata, and embedding each chunk in transformations.\n",
    "\n",
    "- üåü Nodes are a first-class citizen in LlamaIndex, allowing direct definition or parsing from Documents.\n",
    "\n",
    "- üîÑ Transformation inputs and outputs are `Node` objects (Note: `Document` is subclass of `Node`).\n",
    "\n",
    "- üõ†Ô∏è Nodes are \"chunks\" of Documents, including text, images, etc., plus metadata and relationships.\n",
    "\n",
    "- üìä `NodeParser` classes convert Documents into Nodes with all necessary attributes. There are [a number of](https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/modules.html) `NodeParser`'s you can choose from!\n",
    "\n",
    "- üìë High-level API: Use `.from_documents()` for automatic parsing and chunking of Document objects.\n",
    "\n",
    "- üîç Underlying process splits Document into Node objects, maintaining text and metadata with a link to their parent Document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "parser = SentenceSplitter(\n",
    "    chunk_size=128, # in tokens\n",
    "    chunk_overlap=16, #in tokens\n",
    "    paragraph_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "nodes = parser.get_nodes_from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(nodes[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[42].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also choose to construct Node objects manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n",
    "\n",
    "node1 = TextNode(text=\"Dad is married to Mom\", id_=\"001\")\n",
    "\n",
    "node2 = TextNode(text=\"Dad is Son's dad\", id_=\"002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NodeRelationships\n",
    "\n",
    "You can set relationships between nodes.\n",
    "\n",
    "- üåê NodeRelationships assign connections between chunks of text. It's useful for:\n",
    "  - Documents organized in a hierarchical manner (e.g., book, chapter, section, subsection)\n",
    "  - Maintaining sequential order\n",
    "  - Other complex relationships (ie, in legal documents for links a clause or other cases) \n",
    "\n",
    "- üîç NodeRelationships help retrieve not just the relevant section, but also related sections that might provide additional context or information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(\n",
    "    node_id=node2.node_id\n",
    ")\n",
    "\n",
    "node2.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(\n",
    "    node_id=node1.node_id\n",
    ")\n",
    "nodes = [node1, node2]\n",
    "\n",
    "node2.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(\n",
    "    node_id=node1.node_id, metadata={\"Romie\": \"Mom\", \"Harpreet\": \"Dad\", \"Jind\":\"Daughter\", \"Jugaad\":\"Son\"}, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of clean up, let's just go ahead and delete the text files we downloaded since we won't need them going forward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
